{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out - метод проверки cпособности обобщать модели машинного обучения. То есть определять то, насколько хорошо наши модели могут \"растянуть\" данные в случае если их мало.\n",
    "\n",
    "#### Достоин ты чего, друже?\n",
    "Обеспечивает более точную оценку на основе того, что мы в разных итерациях собираем различных тестовые и тренирвочные выборки, т к не опирается на единственный тестовый набор, который в случае немногочисленных тренировочных данных достаточно хорошо обучится т е фиксит отчасти проблему недообучения\n",
    "\n",
    "#### Чем грешишь, приятель?\n",
    "мы многоразово перебираем наши датасеты и следовательно очень высоко алгоритмическое и временный показатель перебора для обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search - техника подбора гиперпараметров для поиска наиболее лучшей комбинации параметров. Оно ищет из определенного набора параметров лучшую комбинацию и проверяет каждую комбинацию по методу перекрестной валидации(cross_val да, да? не уверен, вроде да)\n",
    "\n",
    "Нужно определить гиперпараметры для тюнинга со значениями\n",
    "i e param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "создать сетку всех комбинаций\n",
    "натренировать и обучить модель для каждой комбинации параметров\n",
    "выбрать лучшую\n",
    "\n",
    "\n",
    "#### Достоинства:\n",
    "Супер жадный алгоритм найдет лучшую комбинацию параметров\n",
    "работает хорошо на небольшом наборе гиперпараметров\n",
    "\n",
    "#### Недостатки:\n",
    "Супер жадный алгоритм ибо перебирает N параметров на M значений и следовательно сложность N^M в случае квадратичной матрицы т е если кол-во параметров совпадает с кол-вом значений и в каждом наборе параметров одинаковок кол-во значений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Grid Search - схож чем-то с алгоритмом случайного леса. Заместо перебора всех параметров он рандомит случайные комбинации\n",
    "\n",
    "#### Достоинства:\n",
    "Намного менее жаден в сравнении с grid search\n",
    "\n",
    "#### Недостатки:\n",
    "Не даст лучший результат в сравнении с grid search\n",
    "\n",
    "Алгоритм имхо улучшенная версия Grid Search с точки зрения вычислительных затрат и полезен в сферах, нацеленных на объемы данных, а не результат. Например в медицине где крайне важна точно лучше GS, нежели RGS, а в недвижке уже RGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization - оптимизация, которая предсказывает какие гиперпараметры будут лучше\n",
    "\n",
    "В начале берет несколько случайных гиперпараметров\n",
    "Обучает модели для каждого из них и оценивает ее качество\n",
    "На основе этого подбирает умнее параметры\n",
    "\n",
    "#### Достоинства:\n",
    "Быстрее, т к тестирует не все параметры\n",
    "Эффективна на небольших датасетах\n",
    "\n",
    "#### Недостатки:\n",
    "Требует больше вычислений на каждой итерации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain classification of feature selection methods - процесс отбора наиболее важных фич\n",
    "### Подразделяются на 3 категории:\n",
    "#### методы фильтрации\n",
    "выбирают фичи непосредственно перед обучением\n",
    "используют статистические метрики для сравнения фич\n",
    "быстры\n",
    "###### Пример\n",
    "Variance Threshold - ремувает фичи с низкой дисперсией. Т е если значения параметра очень однородны, то сам параметр мало на что влияет\n",
    "Correalation Coeff - ремувает высоко коррелирующие фичи\n",
    "Chi Square Test - сравнивает зависимость фич от таргета\n",
    "Mutual Information - показывает насколько сильно фича влияет на результат\n",
    "#### методы обертки\n",
    "использует непосредственно МЛ для выбора фич\n",
    "###### Пример\n",
    "Forward Seelection - добавляет по одной фиче за раз и оставляет те, что наиболее ценны\n",
    "Backward Elimination - Избавляется от наименее важных фич с течением времени\n",
    "Recurvive Feature Elimination(RFE) - использует МЛ для избавлениях от наименее ценных фич\n",
    "#### методы эмбеддеда\n",
    "Выбор фич имплементирован в процесс обучения\n",
    "###### Пример\n",
    "L1 Regulation (Lasso) - Ставит в 0 наименее важные фичи по определенному трэшхолду(alpha)\n",
    "Decision Tree Feature Importance\n",
    "Gradient Boosting Methods - дает показатель ценности каждой фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson vs Chi Square\n",
    "Pearson - Показательные фичи, показывает линейную зависимость фич\n",
    "Chi Square - Категориальные фичи, показывает зависимость между категориями фич\n",
    "\n",
    "### Pearson (r coef)\n",
    "Value range - -1...+1\n",
    "+1 - позитивная корреляция(оба улучшаются)\n",
    "-1 - негативная корреляция(с увеличением одного, другое падает)\n",
    "0 - нет корреляции\n",
    "\n",
    "r = (E(Xi - meanX) * (Yi - meanY)) / ((sqrt(E(Xi - meanX)^2) * sqrt(E(Yi - meanY)^2)))\n",
    "\n",
    "### Chi Square (Chi2)\n",
    "Value range - 0...&\n",
    "чем выше, тем сильнее ассоциация\n",
    "X2 = E((Oi - Ei)^2 / Ei), где\n",
    "X2 - хи квадрат\n",
    "Oi - наблюдаемая частота\n",
    "Ei - ожидаемая частота"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso (L1 / Least Absolute Shrinkage ans Selection Operator) - техника регулизации для помощи в выборе фич с подчищением наименее важных, зануляя их коэффициент\n",
    "Добавляет погрешность в модель регрессии, заставляя некоторые коэффициенты занулиться. Убирает неважные фичи\n",
    "Чем выше альфа, тем выше риск недообучения(больше фич отфильтруются)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain what permutation significance is - метод для определения достаточно ли наблюдаемый результат статистически значим путем перетасовки данных и перерасчета тестовой статистики\n",
    "Если наблюдаемый результат редкий, то он вероятно статистически значимый\n",
    "Используем метрики на наших данных\n",
    "Шафлим значениям в рандомной порядке дабы избежать ассоциаций между данными\n",
    "Используем метрики для шафленных данных\n",
    "Повторить N раз\n",
    "сравнить итоговую и изначальную статистику\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
