{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36754f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3b97fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_scores.csv\")\n",
    "X = np.array(df['math'])\n",
    "y = np.array(df['cs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "151b9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, learning_rate=0.01, max_iter=1000, tol=1e-42):\n",
    "    m_curr = b_curr = 0\n",
    "    n = len(x)\n",
    "    prev_cost = 0\n",
    "\n",
    "    for i in tqdm(range(max_iter)):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "\n",
    "        # mse cost function\n",
    "        cost = (1/n) * sum([val**2 for val in (y - y_predicted)])\n",
    "\n",
    "        if i != 0 and cost > prev_cost:\n",
    "            print(f\"Cost increased at iteration {i}, stopping optimization.\")\n",
    "            break\n",
    "        prev_cost = cost\n",
    "        # Gradient descent\n",
    "        # m = m - learning_rate * dm\n",
    "        # b = b - learning_rate * db\n",
    "        # dm = -(2/n) * sum(x * (y - y_predicted))\n",
    "        # db = -(2/n) * sum(y - y_predicted)\n",
    "        md = -(2/n) * sum(x * (y - y_predicted))\n",
    "        bd = -(2/n) * sum(y - y_predicted)\n",
    "\n",
    "        m_curr -= learning_rate * md\n",
    "        b_curr -= learning_rate * bd\n",
    "    \n",
    "        if i % (max_iter / 10) == 0:\n",
    "            print(f\"Iteration {i}: m = {m_curr}, b = {b_curr}, cost = {cost}\")\n",
    "        # Check for convergence\n",
    "        if abs(md) < tol and abs(bd) < tol:\n",
    "            print(f\"Converged after {i} iterations.\")\n",
    "            break\n",
    "        # Check for numerical stability\n",
    "        if math.isclose(m_curr, 1e-20) and math.isclose(b_curr, 1e-20):\n",
    "            print(\"Parameters are close to zero, stopping optimization.\")\n",
    "            break\n",
    "\n",
    "    return m_curr, b_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7db46f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28324/1000000 [00:00<00:06, 141250.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: m = 0.692426, b = 0.009786, cost = 5199.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 112770/1000000 [00:00<00:06, 131441.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100000: m = 1.0297435498235956, b = 1.064292279784712, cost = 31.64607835452838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 216049/1000000 [00:01<00:06, 118954.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200000: m = 1.0231124742338216, b = 1.534219394369305, cost = 31.61284457607173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 314920/1000000 [00:02<00:04, 140470.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 300000: m = 1.0201434308790205, b = 1.7446277900977334, cost = 31.606181959174577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 416339/1000000 [00:03<00:04, 142646.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 400000: m = 1.0188140510034114, b = 1.8388374911747587, cost = 31.604846255984036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 516263/1000000 [00:03<00:03, 138488.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500000: m = 1.0182188253221103, b = 1.8810195901651325, cost = 31.60457847786609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 615563/1000000 [00:04<00:02, 141479.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 600000: m = 1.0179523148850405, b = 1.8999064930518983, cost = 31.60452479444228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 716147/1000000 [00:05<00:02, 134700.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 700000: m = 1.0178329856704276, b = 1.9083630447454378, cost = 31.60451403213652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 815195/1000000 [00:06<00:01, 138544.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 800000: m = 1.0177795563878196, b = 1.9121494393160319, cost = 31.604511874538925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 914533/1000000 [00:06<00:00, 142350.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 900000: m = 1.0177556335936464, b = 1.9138447856420389, cost = 31.60451144198966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:07<00:00, 133518.59it/s]\n"
     ]
    }
   ],
   "source": [
    "m, b = gradient_descent(X, y, learning_rate=0.00007, max_iter=1_000_000, tol=1e-42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "29bf4f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Coefficients: 1.0177362378569323, Intercept: 1.9152193111569318\n",
      "Custom Gradient Descent Coefficients: 1.0177449223071622, Intercept: 1.9146038667115937\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(df[['math']], df[['cs']])\n",
    "print(f\"Linear Regression Coefficients: {lr.coef_[0][0]}, Intercept: {lr.intercept_[0]}\")\n",
    "print(f\"Custom Gradient Descent Coefficients: {m}, Intercept: {b}\")\n",
    "assert math.isclose(m, lr.coef_[0][0], rel_tol=1e-5), \"Coefficients do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340af72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
